{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style> \n",
    "    table {display: block;} \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM-CRF models for Sequence Tagging\n",
    "## Zhiheng Huangm Wei Xu and Kai Yu\n",
    "### Code\n",
    "- https://github.com/guillaumegenthial/tf_ner/tree/master/models/lstm_crf\n",
    "- https://github.com/sarveshsparab/BiLSTMCRFSeqTag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding paths to sys paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supressing warning level messages in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating an object of the NER parent class implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import BiLSTMCRFSeqTag\n",
    "from masked_conv import masked_conv1d_and_max\n",
    "from ner import NER\n",
    "\n",
    "blcst = BiLSTMCRFSeqTag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the input files for the model\n",
    "### 3 files required\n",
    "- train : For the model to train\n",
    "- dev : For the model to validate the training\n",
    "- test : To evaluate the performance to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = dict()\n",
    "file_dict['train'] = '../data/example/tester.txt'\n",
    "file_dict['test'] = '../data/example/tester.txt'\n",
    "file_dict['dev'] = '../data/example/tester.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the dataset\n",
    "- Description\n",
    "    * Reads a dataset in preparation for train or test. Returns data in proper format for train or test.\n",
    "- Returns\n",
    "    * A dictionary of file_dict keys as keys and values as lists of lines, where in each line is further tokenized on the column delimiter and extracted as a list\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">Standard</td>\n",
    "            <td>file_dict</td>\n",
    "            <td>-</td>\n",
    "            <td>A dictionary with input file locations</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dataset_name</td>\n",
    "            <td>CoNLL03</td>\n",
    "            <td>Name of the dataset required for calling appropriate utils, converters</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">kwargs</td>\n",
    "            <td>fileHasHeaders</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to check if input file has headers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>columnDelimiter</td>\n",
    "            <td>`space`</td>\n",
    "            <td>Delimiter in the data input</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:151 - read_dataset() ] Invoked read_dataset method\n",
      "[main.py:152 - read_dataset() ] With parameters : \n",
      "[main.py:153 - read_dataset() ] {'train': '../data/example/tester.txt', 'test': '../data/example/tester.txt', 'dev': '../data/example/tester.txt'}\n",
      "[main.py:154 - read_dataset() ] CoNLL2003\n",
      "[main.py:155 - read_dataset() ] ()\n",
      "[main.py:156 - read_dataset() ] {}\n",
      "[main.py:179 - read_dataset() ] Returning data : \n",
      "[main.py:180 - read_dataset() ] {'train': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'test': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'dev': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']]}\n"
     ]
    }
   ],
   "source": [
    "data = blcst.read_dataset(file_dict, \"CoNLL2003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the ground truth data\n",
    "- Description\n",
    "    * Converts test data into common format for evaluation \\[i.e. same format as predict()\\] \n",
    "    * This added step/layer of abstraction is required due to the refactoring of read_dataset_train() and read_dataset_test() back to the single method of read_dataset() along with the requirement on the format of the output of predict() and therefore the input format requirement of evaluate()\n",
    "- Returns\n",
    "    * \\[tuple,...\\], i.e. list of tuples. \\[SAME format as output of predict()\\]\n",
    "    * Each tuple is (start index, span, mention text, mention type)\n",
    "    * Where:\n",
    "         - start index: int, the index of the first character of the mention span. None if not applicable.\n",
    "         - span: int, the length of the mention. None if not applicable.\n",
    "         - mention text: str, the actual text that was identified as a named entity. Required.\n",
    "         - mention type: str, the entity/mention type. None if not applicable.\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>data in proper format for train or test. [i.e. format of output from read_dataset]</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"4\">kwargs</td>\n",
    "            <td>wordPosition</td>\n",
    "            <td>0</td>\n",
    "            <td>Column number with the mention word</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tagPosition</td>\n",
    "            <td>3</td>\n",
    "            <td>Column number with the entity tag</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writeGroundTruthToFile</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to enable writing ground truths to a file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruthPath</td>\n",
    "            <td>../results/groundTruths.txt</td>\n",
    "            <td>Location to save the ground truths file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:95 - convert_ground_truth() ] Invoked convert_ground_truth method\n",
      "[main.py:96 - convert_ground_truth() ] With parameters : \n",
      "[main.py:97 - convert_ground_truth() ] {'train': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'test': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'dev': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:98 - convert_ground_truth() ] (None,)\n",
      "[main.py:99 - convert_ground_truth() ] {}\n",
      "[main.py:109 - convert_ground_truth() ] Returning ground truths for the test input file :\n",
      "[main.py:110 - convert_ground_truth() ] [[None, None, 'in', 'O'], [None, None, 'New', 'B-LOC'], [None, None, 'York', 'I-LOC'], [None, None, 'Raph', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'London', 'B-LOC'], [None, None, 'Marie', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'Paris', 'B-LOC'], [None, None, 'Dominik', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'Berlin', 'B-LOC'], [None, None, 'Raul', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'Mexico', 'B-LOC'], [None, None, 'Laure', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'Milan', 'B-LOC'], [None, None, 'Alexandr', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'Moscow', 'B-LOC'], [None, None, 'Ines', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'Casablanca', 'B-LOC'], [None, None, 'Clovis', 'B-PER'], [None, None, 'lives', 'O'], [None, None, 'in', 'O'], [None, None, 'San', 'B-LOC'], [None, None, 'Francisco', 'I-LOC']]\n"
     ]
    }
   ],
   "source": [
    "groundTruth = blcst.convert_ground_truth(data, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "- Description\n",
    "    * Trains he model on the parsed data\n",
    "    * Calls the internal save_model method to save the trained model for predictions\n",
    "- Returns\n",
    "    * model   - Trained ELMo model object\n",
    "    * sess    - Tensorflow session object (will be used to maintain the tensorflow session instance)\n",
    "    * saver   - Tensorflow saver instance (will be used to load model again)\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>Parsed input data in the format returned by read_dataset method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"20\">kwargs</td>\n",
    "            <td>dimChars</td>\n",
    "            <td>100</td>\n",
    "            <td>Model character level dimensionality</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dim</td>\n",
    "            <td>300</td>\n",
    "            <td>Model dimensionality</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dropout</td>\n",
    "            <td>0.5</td>\n",
    "            <td>Model dropout rate</td>\n",
    "            <td>✖<td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>epochs</td>\n",
    "            <td>25</td>\n",
    "            <td>Number of epoch to run for training</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>batchSize</td>\n",
    "            <td>20</td>\n",
    "            <td>Training batch sizes</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>filterNum</td>\n",
    "            <td>50</td>\n",
    "            <td>Filter area size</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>lstmSize</td>\n",
    "            <td>100</td>\n",
    "            <td>State size of the Multi-LSTM layers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabWordsPath</td>\n",
    "            <td>../dev/vocab.words.txt</td>\n",
    "            <td>Location of the parsed words set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabCharsPath</td>\n",
    "            <td>../dev/vocab.chars.txt</td>\n",
    "            <td>Location of the parsed charcters set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabTagsPath</td>\n",
    "            <td>../dev/vocab.tags.txt</td>\n",
    "            <td>Location of the parsed tags set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveCompressedNPZPath</td>\n",
    "            <td>../dev/glove.npz</td>\n",
    "            <td>Location of the extracted Glove embeddings from input data in compressed form</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>paramsPath</td>\n",
    "            <td>../results/params.json</td>\n",
    "            <td>Location where model parameters get saved</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>inputFileWordsPath</td>\n",
    "            <td>../dev/{}.words.txt</td>\n",
    "            <td>Location of the extracted words from the input files</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>inputFileTagsPath</td>\n",
    "            <td>../dev/{}.tags.txt</td>\n",
    "            <td>Location of the extracted tags from the input files</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>checkpointPath</td>\n",
    "            <td>../results/checkpoint</td>\n",
    "            <td>Location to save intermediate checkpoints</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>modelPath</td>\n",
    "            <td>../results/saved_model</td>\n",
    "            <td>Location to save the best model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveEmbedPath</td>\n",
    "            <td>../resources/glove/glove.840B.300d.txt</td>\n",
    "            <td>Location fo the glove embedding file</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>wordPosition</td>\n",
    "            <td>0</td>\n",
    "            <td>Column number with the mention word</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tagPosition</td>\n",
    "            <td>3</td>\n",
    "            <td>Column number with the entity tag</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writeInputToFile</td>\n",
    "            <td>true</td>\n",
    "            <td>Flag to toggle behaviour of the internal data_converter method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:217 - train() ] Invoked train method\n",
      "[main.py:218 - train() ] With parameters : \n",
      "[main.py:219 - train() ] {'train': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'test': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'dev': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:220 - train() ] (None,)\n",
      "[main.py:221 - train() ] {}\n",
      "[main.py:466 - data_converter() ] Invoked data_converter method\n",
      "[main.py:467 - data_converter() ] With parameters : \n",
      "[main.py:468 - data_converter() ] {'train': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'test': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']], 'dev': [['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['New', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['York', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raph', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['London', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Marie', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Paris', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Dominik', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Berlin', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Raul', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Mexico', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Laure', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Milan', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Alexandr', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Moscow', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Ines', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Casablanca', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], [], ['Clovis', '-', '-', 'B-PER', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['lives', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['in', '-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['San', '-', '-', 'B-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['Francisco', '-', '-', 'I-LOC', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:469 - data_converter() ] (None,)\n",
      "[main.py:470 - data_converter() ] {}\n",
      "[main.py:472 - data_converter() ] Parsing input and building the corresponding data files\n",
      "[main.py:475 - data_converter() ] Building vocab files\n",
      "[main.py:526 - build_vocab_files() ] Build vocab words (may take a while)\n",
      "[main.py:537 - build_vocab_files() ] - done. Kept 21 out of 21\n",
      "[main.py:540 - build_vocab_files() ] Build vocab chars\n",
      "[main.py:547 - build_vocab_files() ] - done. Found 32 chars\n",
      "[main.py:554 - build_vocab_files() ] Build vocab tags (may take a while)\n",
      "[main.py:562 - build_vocab_files() ] - done. Found 4 tags.\n",
      "[main.py:479 - data_converter() ] Fetching glove embeddings from file : ../resources/glove/glove.840B.300d.txt\n",
      "[main.py:573 - incorporate_glove_embeddings() ] Reading GloVe file (may take a while)\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 0\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 100000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 200000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 300000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 400000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 500000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 600000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 700000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 800000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 900000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1000000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1100000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1200000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1300000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1400000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1500000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1600000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1700000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1800000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 1900000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 2000000\n",
      "[main.py:577 - incorporate_glove_embeddings() ] - At line 2100000\n",
      "[main.py:587 - incorporate_glove_embeddings() ] - done. Found 21 vectors for 21 words\n",
      "[estimator.py:201 - __init__() ] Using config: {'_model_dir': '../results/checkpoint', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000024DE3918D30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "[estimator_training.py:185 - should_run_distribute_coordinator() ] Not using Distribute Coordinator.\n",
      "[training.py:610 - run() ] Running training and evaluation locally (non-distributed).\n",
      "[training.py:698 - run_local() ] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 120.\n",
      "[estimator.py:1111 - _call_model_fn() ] Calling model_fn.\n",
      "[estimator.py:1113 - _call_model_fn() ] Done calling model_fn.\n",
      "[basic_session_run_hooks.py:527 - __init__() ] Create CheckpointSaverHook.\n",
      "[monitored_session.py:222 - finalize() ] Graph was finalized.\n",
      "[saver.py:1270 - restore() ] Restoring parameters from ../results/checkpoint\\model.ckpt-12\n",
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "[session_manager.py:491 - _try_run_local_init_op() ] Running local_init_op.\n",
      "[session_manager.py:493 - _try_run_local_init_op() ] Done running local_init_op.\n",
      "[basic_session_run_hooks.py:594 - _save() ] Saving checkpoints for 12 into ../results/checkpoint\\model.ckpt.\n",
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\summary\\summary_iterator.py:68: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "[basic_session_run_hooks.py:249 - _log_tensors() ] loss = 1.9870079, step = 13\n",
      "[basic_session_run_hooks.py:594 - _save() ] Saving checkpoints for 24 into ../results/checkpoint\\model.ckpt.\n",
      "[estimator.py:1111 - _call_model_fn() ] Calling model_fn.\n",
      "[estimator.py:1113 - _call_model_fn() ] Done calling model_fn.\n",
      "[evaluation.py:257 - _evaluate_once() ] Starting evaluation at 2019-04-29T09:50:03Z\n",
      "[monitored_session.py:222 - finalize() ] Graph was finalized.\n",
      "[saver.py:1270 - restore() ] Restoring parameters from ../results/checkpoint\\model.ckpt-24\n",
      "[session_manager.py:491 - _try_run_local_init_op() ] Running local_init_op.\n",
      "[session_manager.py:493 - _try_run_local_init_op() ] Done running local_init_op.\n",
      "[evaluation.py:277 - _evaluate_once() ] Finished evaluation at 2019-04-29-09:50:04\n",
      "[estimator.py:1979 - _write_dict_to_summary() ] Saving dict for global step 24: acc = 1.0, f1 = 1.0, global_step = 24, loss = 0.40233204, precision = 1.0, recall = 1.0\n",
      "[estimator.py:2039 - _write_checkpoint_path_to_summary() ] Saving 'checkpoint_path' summary for global step 24: ../results/checkpoint\\model.ckpt-24\n",
      "[estimator.py:359 - train() ] Loss for final step: 0.5765177.\n",
      "[main.py:264 - train() ] Training done! ... Saving trained model\n",
      "[main.py:411 - save_model() ] Invoked save_model method\n",
      "[main.py:412 - save_model() ] With parameters : \n",
      "[main.py:413 - save_model() ] ../results/saved_model\n",
      "[main.py:414 - save_model() ] (None,)\n",
      "[main.py:415 - save_model() ] {}\n",
      "[estimator.py:1739 - maybe_overwrite_model_dir_and_session_config() ] Using default config.\n",
      "[estimator.py:201 - __init__() ] Using config: {'_model_dir': '../results/checkpoint', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000024DDBE256A0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "[estimator.py:1111 - _call_model_fn() ] Calling model_fn.\n",
      "[estimator.py:1113 - _call_model_fn() ] Done calling model_fn.\n",
      "[export.py:587 - _log_signature_report() ] Signatures INCLUDED in export for Classify: None\n",
      "[export.py:587 - _log_signature_report() ] Signatures INCLUDED in export for Regress: None\n",
      "[export.py:587 - _log_signature_report() ] Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "[export.py:587 - _log_signature_report() ] Signatures INCLUDED in export for Train: None\n",
      "[export.py:587 - _log_signature_report() ] Signatures INCLUDED in export for Eval: None\n",
      "[saver.py:1270 - restore() ] Restoring parameters from ../results/checkpoint\\model.ckpt-24\n",
      "[builder_impl.py:654 - _maybe_save_assets() ] Assets added to graph.\n",
      "[builder_impl.py:763 - copy_assets_to_destination_dir() ] Assets written to: ../results/saved_model\\temp-b'1556531404'\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[builder_impl.py:414 - save() ] SavedModel written to: ../results/saved_model\\temp-b'1556531404'\\saved_model.pb\n",
      "[main.py:428 - save_model() ] Model saved at location : ../results/saved_model\n"
     ]
    }
   ],
   "source": [
    "blcst.train(data, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions\n",
    "- Description\n",
    "    * Parses and converts the input sentence provided in a file for predicting the NER tags\n",
    "    * Calls the internal load_model method to load the trained model for predictions\n",
    "- Returns\n",
    "    * \\[tuple,...\\], i.e. list of tuples.\n",
    "    * Each tuple is (start index, span, mention text, mention type)\n",
    "    * Where:\n",
    "         - start index: int, the index of the first character of the mention span. None if not applicable.\n",
    "         - span: int, the length of the mention. None if not applicable.\n",
    "         - mention text: str, the actual text that was identified as a named entity. Required.\n",
    "         - mention type: str, the entity/mention type. None if not applicable.\n",
    "\n",
    "         `NOTE: len(predictions) should equal len(data) AND the ordering should not change [important for evaluation. See note in evaluate() about parallel arrays.]`\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>The file location with the input text in the common format for prediction</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"11\">kwargs</td>\n",
    "            <td>fileHasHeaders</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to check if input file has headers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>loadModelFrom</td>\n",
    "            <td>checkpoint</td>\n",
    "            <td>Flag to decide to choose to load model from 'checkpoint' or 'saved_model'</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabWordsPath</td>\n",
    "            <td>../dev/vocab.words.txt</td>\n",
    "            <td>Location of the parsed words set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabCharsPath</td>\n",
    "            <td>../dev/vocab.chars.txt</td>\n",
    "            <td>Location of the parsed charcters set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabTagsPath</td>\n",
    "            <td>../dev/vocab.tags.txt</td>\n",
    "            <td>Location of the parsed tags set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveCompressedNPZPath</td>\n",
    "            <td>../dev/glove.npz</td>\n",
    "            <td>Location of the extracted Glove embeddings from input data in compressed form</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>paramsPath</td>\n",
    "            <td>../results/params.json</td>\n",
    "            <td>Location where model parameters get saved</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>checkpointPath</td>\n",
    "            <td>../results/checkpoint</td>\n",
    "            <td>Location to save intermediate checkpoints</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>modelPath</td>\n",
    "            <td>../results/saved_model</td>\n",
    "            <td>Location to save the best model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writePredsToFile</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to enable writing predictions to file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>predsPath</td>\n",
    "            <td>../results/predictions.txt</td>\n",
    "            <td>Location where to write predictions into</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:301 - predict() ] Invoked predict method\n",
      "[main.py:302 - predict() ] With parameters : \n",
      "[main.py:303 - predict() ] ../data/sample/ner_test_input.txt\n",
      "[main.py:304 - predict() ] (None,)\n",
      "[main.py:305 - predict() ] {'writeInputToFile': False}\n",
      "[main.py:431 - load_model() ] Invoked load_model method\n",
      "[main.py:432 - load_model() ] With parameters : \n",
      "[main.py:433 - load_model() ] {'writeInputToFile': False}\n",
      "[estimator.py:1739 - maybe_overwrite_model_dir_and_session_config() ] Using default config.\n",
      "[estimator.py:201 - __init__() ] Using config: {'_model_dir': '../results/checkpoint', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000024DDB0C47B8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "[main.py:451 - load_model_from_checkpoint() ] Loaded model from previous checkpoint location : ../results/checkpoint\n",
      "[estimator.py:974 - _validate_features_in_predict_input() ] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "[estimator.py:1111 - _call_model_fn() ] Calling model_fn.\n",
      "[estimator.py:1113 - _call_model_fn() ] Done calling model_fn.\n",
      "[monitored_session.py:222 - finalize() ] Graph was finalized.\n",
      "[saver.py:1270 - restore() ] Restoring parameters from ../results/checkpoint\\model.ckpt-24\n",
      "[session_manager.py:491 - _try_run_local_init_op() ] Running local_init_op.\n",
      "[session_manager.py:493 - _try_run_local_init_op() ] Done running local_init_op.\n",
      "[main.py:774 - pretty_print() ] words: Yes   they  did   /.    and   they  were  not   the   first company that  approached me    /.    but   I     am    not   selling medicine or    pharmaceuticals /.    I     'm    sort  of    about selling a     full  body  approach to    wellness /.    Um    there 's    a     big   gap   between those that  are   mentally ill   and   the   general population /.    A     much  better looking News  Night I     might add   as    Paula Zahn  sits  in for   Anderson and   Aaron /.    They  're   both  off   /-    Look  at    that  /.   \n",
      "[main.py:775 - pretty_print() ] preds: B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER   B-PER B-PER      B-PER B-PER B-PER B-PER B-PER B-PER B-PER   B-PER    B-PER B-PER           B-PER B-PER B-PER B-PER B-PER B-PER B-PER   B-PER B-PER B-PER B-PER    B-PER B-PER    B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER   B-PER B-PER B-PER B-PER    B-PER B-PER B-PER B-PER   B-PER      B-PER B-PER B-PER B-PER  B-PER   B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER B-PER O  B-LOC B-PER    B-LOC B-LOC B-LOC B-PER B-LOC B-PER B-LOC B-LOC B-LOC B-LOC B-LOC B-LOC\n",
      "[main.py:350 - predict() ] Returning predictions :\n",
      "[main.py:351 - predict() ] [[None, None, 'Yes', 'O', 'B-PER'], [None, None, 'they', 'O', 'B-PER'], [None, None, 'did', 'O', 'B-PER'], [None, None, '/.', 'O', 'B-PER'], [None, None, 'and', 'O', 'B-PER'], [None, None, 'they', 'O', 'B-PER'], [None, None, 'were', 'O', 'B-PER'], [None, None, 'not', 'O', 'B-PER'], [None, None, 'the', 'O', 'B-PER'], [None, None, 'first', 'B-ORDINAL', 'B-PER'], [None, None, 'company', 'O', 'B-PER'], [None, None, 'that', 'O', 'B-PER'], [None, None, 'approached', 'O', 'B-PER'], [None, None, 'me', 'O', 'B-PER'], [None, None, '/.', 'O', 'B-PER'], [None, None, 'but', 'O', 'B-PER'], [None, None, 'I', 'O', 'B-PER'], [None, None, 'am', 'O', 'B-PER'], [None, None, 'not', 'O', 'B-PER'], [None, None, 'selling', 'O', 'B-PER'], [None, None, 'medicine', 'O', 'B-PER'], [None, None, 'or', 'O', 'B-PER'], [None, None, 'pharmaceuticals', 'O', 'B-PER'], [None, None, '/.', 'O', 'B-PER'], [None, None, 'I', 'O', 'B-PER'], [None, None, \"'m\", 'O', 'B-PER'], [None, None, 'sort', 'O', 'B-PER'], [None, None, 'of', 'O', 'B-PER'], [None, None, 'about', 'O', 'B-PER'], [None, None, 'selling', 'O', 'B-PER'], [None, None, 'a', 'O', 'B-PER'], [None, None, 'full', 'O', 'B-PER'], [None, None, 'body', 'O', 'B-PER'], [None, None, 'approach', 'O', 'B-PER'], [None, None, 'to', 'O', 'B-PER'], [None, None, 'wellness', 'O', 'B-PER'], [None, None, '/.', 'O', 'B-PER'], [None, None, 'Um', 'O', 'B-PER'], [None, None, 'there', 'O', 'B-PER'], [None, None, \"'s\", 'O', 'B-PER'], [None, None, 'a', 'O', 'B-PER'], [None, None, 'big', 'O', 'B-PER'], [None, None, 'gap', 'O', 'B-PER'], [None, None, 'between', 'O', 'B-PER'], [None, None, 'those', 'O', 'B-PER'], [None, None, 'that', 'O', 'B-PER'], [None, None, 'are', 'O', 'B-PER'], [None, None, 'mentally', 'O', 'B-PER'], [None, None, 'ill', 'O', 'B-PER'], [None, None, 'and', 'O', 'B-PER'], [None, None, 'the', 'O', 'B-PER'], [None, None, 'general', 'O', 'B-PER'], [None, None, 'population', 'O', 'B-PER'], [None, None, '/.', 'O', 'B-PER'], [None, None, 'A', 'O', 'B-PER'], [None, None, 'much', 'O', 'B-PER'], [None, None, 'better', 'O', 'B-PER'], [None, None, 'looking', 'O', 'B-PER'], [None, None, 'News', 'B-WORK_OF_ART', 'B-PER'], [None, None, 'Night', 'I-WORK_OF_ART', 'B-PER'], [None, None, 'I', 'O', 'B-PER'], [None, None, 'might', 'O', 'B-PER'], [None, None, 'add', 'O', 'B-PER'], [None, None, 'as', 'O', 'B-PER'], [None, None, 'Paula', 'B-PERSON', 'B-PER'], [None, None, 'Zahn', 'I-PERSON', 'B-PER'], [None, None, 'sits', 'O', 'B-PER'], [None, None, 'in', 'O', 'O'], [None, None, 'for', 'O', 'B-LOC'], [None, None, 'Anderson', 'B-PERSON', 'B-PER'], [None, None, 'and', 'O', 'B-LOC'], [None, None, 'Aaron', 'B-PERSON', 'B-LOC'], [None, None, '/.', 'O', 'B-LOC'], [None, None, 'They', 'O', 'B-PER'], [None, None, \"'re\", 'O', 'B-LOC'], [None, None, 'both', 'O', 'B-PER'], [None, None, 'off', 'O', 'B-LOC'], [None, None, '/-', 'O', 'B-LOC'], [None, None, 'Look', 'O', 'B-LOC'], [None, None, 'at', 'O', 'B-LOC'], [None, None, 'that', 'O', 'B-LOC'], [None, None, '/.', 'O', 'B-LOC']]\n"
     ]
    }
   ],
   "source": [
    "predictions = blcst.predict(\"../data/sample/ner_test_input.txt\", None, writeInputToFile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model\n",
    "- Description\n",
    "    * Calculates evaluation metrics on chosen benchmark dataset\n",
    "        - Precision\n",
    "        - Recall\n",
    "        - F1 Score\n",
    "- Returns\n",
    "    * Tuple with metrics (p,r,f1). Each element is float.\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">Standard</td>\n",
    "            <td>predictions</td>\n",
    "            <td>N/A</td>\n",
    "            <td>List of predicted labels</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruths</td>\n",
    "            <td>N/A</td>\n",
    "            <td>List of ground truth labels</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">kwargs</td>\n",
    "            <td>predsPath</td>\n",
    "            <td>../results/predictions.txt</td>\n",
    "            <td>Location from where to read predictions from</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruthPath</td>\n",
    "            <td>../results/groundTruths.txt</td>\n",
    "            <td>Location from where to read ground truths from</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:379 - evaluate() ] Invoked evaluate method\n",
      "[main.py:380 - evaluate() ] With parameters : \n",
      "[main.py:381 - evaluate() ] ['B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'O', 'B-LOC', 'B-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-PER', 'B-LOC', 'B-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC']\n",
      "[main.py:382 - evaluate() ] ['O', 'B-LOC', 'I-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'B-LOC', 'I-LOC']\n",
      "[main.py:383 - evaluate() ] (None,)\n",
      "[main.py:384 - evaluate() ] {}\n",
      "[main.py:405 - evaluate() ] Returning evaluation metrics [P, R, F1] :\n",
      "[main.py:406 - evaluate() ] (22.22222222222222, 47.05882352941176, 30.18867924528302)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22.22222222222222, 47.05882352941176, 30.18867924528302)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blcst.evaluate([col[3] for col in predictions], [col[3] for col in groundTruth], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
