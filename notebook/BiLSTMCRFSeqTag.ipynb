{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    table {display: block;} \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> \n",
    "    table {display: block;} \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM-CRF models for Sequence Tagging\n",
    "## Zhiheng Huangm Wei Xu and Kai Yu\n",
    "### Code\n",
    "- https://github.com/guillaumegenthial/tf_ner/tree/master/models/lstm_crf\n",
    "- https://github.com/sarveshsparab/BiLSTMCRFSeqTag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding paths to sys paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supressing warning level messages in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating an object of the NER parent class implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiLSTMCRFSeqTag import BiLSTMCRFSeqTag\n",
    "from masked_conv import masked_conv1d_and_max\n",
    "from ner import NER\n",
    "\n",
    "blcst = BiLSTMCRFSeqTag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the input files for the model\n",
    "### 3 files required\n",
    "- train : For the model to train\n",
    "- dev : For the model to validate the training\n",
    "- test : To evaluate the performance to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = dict()\n",
    "file_dict['train'] = '../data/example/tester.txt'\n",
    "file_dict['test'] = '../data/example/tester.txt'\n",
    "file_dict['dev'] = '../data/example/tester.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the dataset\n",
    "- Description\n",
    "    * Reads a dataset in preparation for train or test. Returns data in proper format for train or test.\n",
    "- Returns\n",
    "    * A dictionary of file_dict keys as keys and values as lists of lines, where in each line is further tokenized on the column delimiter and extracted as a list\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">Standard</td>\n",
    "            <td>file_dict</td>\n",
    "            <td>-</td>\n",
    "            <td>A dictionary with input file locations</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dataset_name</td>\n",
    "            <td>CoNLL03</td>\n",
    "            <td>Name of the dataset required for calling appropriate utils, converters</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">kwargs</td>\n",
    "            <td>fileHasHeaders</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to check if input file has headers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>columnDelimiter</td>\n",
    "            <td>`space`</td>\n",
    "            <td>Delimiter in the data input</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = blcst.read_dataset(file_dict, \"CoNLL2003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the ground truth data\n",
    "- Description\n",
    "    * Converts test data into common format for evaluation \\[i.e. same format as predict()\\] \n",
    "    * This added step/layer of abstraction is required due to the refactoring of read_dataset_train() and read_dataset_test() back to the single method of read_dataset() along with the requirement on the format of the output of predict() and therefore the input format requirement of evaluate()\n",
    "- Returns\n",
    "    * \\[tuple,...\\], i.e. list of tuples. \\[SAME format as output of predict()\\]\n",
    "    * Each tuple is (start index, span, mention text, mention type)\n",
    "    * Where:\n",
    "         - start index: int, the index of the first character of the mention span. None if not applicable.\n",
    "         - span: int, the length of the mention. None if not applicable.\n",
    "         - mention text: str, the actual text that was identified as a named entity. Required.\n",
    "         - mention type: str, the entity/mention type. None if not applicable.\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>data in proper format for train or test. [i.e. format of output from read_dataset]</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"4\">kwargs</td>\n",
    "            <td>wordPosition</td>\n",
    "            <td>0</td>\n",
    "            <td>Column number with the mention word</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tagPosition</td>\n",
    "            <td>3</td>\n",
    "            <td>Column number with the entity tag</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writeGroundTruthToFile</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to enable writing ground truths to a file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruthPath</td>\n",
    "            <td>../results/groundTruths.txt</td>\n",
    "            <td>Location to save the ground truths file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth = blcst.convert_ground_truth(data, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "- Description\n",
    "    * Trains he model on the parsed data\n",
    "    * Calls the internal save_model method to save the trained model for predictions\n",
    "- Returns\n",
    "    * model   - Trained ELMo model object\n",
    "    * sess    - Tensorflow session object (will be used to maintain the tensorflow session instance)\n",
    "    * saver   - Tensorflow saver instance (will be used to load model again)\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>Parsed input data in the format returned by read_dataset method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"20\">kwargs</td>\n",
    "            <td>dimChars</td>\n",
    "            <td>100</td>\n",
    "            <td>Model character level dimensionality</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dim</td>\n",
    "            <td>300</td>\n",
    "            <td>Model dimensionality</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dropout</td>\n",
    "            <td>0.5</td>\n",
    "            <td>Model dropout rate</td>\n",
    "            <td>✖<td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>epochs</td>\n",
    "            <td>25</td>\n",
    "            <td>Number of epoch to run for training</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>batchSize</td>\n",
    "            <td>20</td>\n",
    "            <td>Training batch sizes</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>filterNum</td>\n",
    "            <td>50</td>\n",
    "            <td>Filter area size</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>lstmSize</td>\n",
    "            <td>100</td>\n",
    "            <td>State size of the Multi-LSTM layers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabWordsPath</td>\n",
    "            <td>../dev/vocab.words.txt</td>\n",
    "            <td>Location of the parsed words set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabCharsPath</td>\n",
    "            <td>../dev/vocab.chars.txt</td>\n",
    "            <td>Location of the parsed charcters set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabTagsPath</td>\n",
    "            <td>../dev/vocab.tags.txt</td>\n",
    "            <td>Location of the parsed tags set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveCompressedNPZPath</td>\n",
    "            <td>../dev/glove.npz</td>\n",
    "            <td>Location of the extracted Glove embeddings from input data in compressed form</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>paramsPath</td>\n",
    "            <td>../results/params.json</td>\n",
    "            <td>Location where model parameters get saved</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>inputFileWordsPath</td>\n",
    "            <td>../dev/{}.words.txt</td>\n",
    "            <td>Location of the extracted words from the input files</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>inputFileTagsPath</td>\n",
    "            <td>../dev/{}.tags.txt</td>\n",
    "            <td>Location of the extracted tags from the input files</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>checkpointPath</td>\n",
    "            <td>../results/checkpoint</td>\n",
    "            <td>Location to save intermediate checkpoints</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>modelPath</td>\n",
    "            <td>../results/saved_model</td>\n",
    "            <td>Location to save the best model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveEmbedPath</td>\n",
    "            <td>../resources/glove/glove.840B.300d.txt</td>\n",
    "            <td>Location fo the glove embedding file</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>wordPosition</td>\n",
    "            <td>0</td>\n",
    "            <td>Column number with the mention word</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tagPosition</td>\n",
    "            <td>3</td>\n",
    "            <td>Column number with the entity tag</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writeInputToFile</td>\n",
    "            <td>true</td>\n",
    "            <td>Flag to toggle behaviour of the internal data_converter method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blcst.train(data, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions\n",
    "- Description\n",
    "    * Parses and converts the input sentence provided in a file for predicting the NER tags\n",
    "    * Calls the internal load_model method to load the trained model for predictions\n",
    "- Returns\n",
    "    * \\[tuple,...\\], i.e. list of tuples.\n",
    "    * Each tuple is (start index, span, mention text, mention type)\n",
    "    * Where:\n",
    "         - start index: int, the index of the first character of the mention span. None if not applicable.\n",
    "         - span: int, the length of the mention. None if not applicable.\n",
    "         - mention text: str, the actual text that was identified as a named entity. Required.\n",
    "         - mention type: str, the entity/mention type. None if not applicable.\n",
    "\n",
    "         `NOTE: len(predictions) should equal len(data) AND the ordering should not change [important for evaluation. See note in evaluate() about parallel arrays.]`\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>The file location with the input text in the common format for prediction</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"11\">kwargs</td>\n",
    "            <td>fileHasHeaders</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to check if input file has headers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>loadModelFrom</td>\n",
    "            <td>checkpoint</td>\n",
    "            <td>Flag to decide to choose to load model from 'checkpoint' or 'saved_model'</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabWordsPath</td>\n",
    "            <td>../dev/vocab.words.txt</td>\n",
    "            <td>Location of the parsed words set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabCharsPath</td>\n",
    "            <td>../dev/vocab.chars.txt</td>\n",
    "            <td>Location of the parsed charcters set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabTagsPath</td>\n",
    "            <td>../dev/vocab.tags.txt</td>\n",
    "            <td>Location of the parsed tags set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveCompressedNPZPath</td>\n",
    "            <td>../dev/glove.npz</td>\n",
    "            <td>Location of the extracted Glove embeddings from input data in compressed form</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>paramsPath</td>\n",
    "            <td>../results/params.json</td>\n",
    "            <td>Location where model parameters get saved</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>checkpointPath</td>\n",
    "            <td>../results/checkpoint</td>\n",
    "            <td>Location to save intermediate checkpoints</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>modelPath</td>\n",
    "            <td>../results/saved_model</td>\n",
    "            <td>Location to save the best model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writePredsToFile</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to enable writing predictions to file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>predsPath</td>\n",
    "            <td>../results/predictions.txt</td>\n",
    "            <td>Location where to write predictions into</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = blcst.predict(\"../data/sample/ner_test_input.txt\", None, writeInputToFile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model\n",
    "- Description\n",
    "    * Calculates evaluation metrics on chosen benchmark dataset\n",
    "        - Precision\n",
    "        - Recall\n",
    "        - F1 Score\n",
    "- Returns\n",
    "    * Tuple with metrics (p,r,f1). Each element is float.\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">Standard</td>\n",
    "            <td>predictions</td>\n",
    "            <td>N/A</td>\n",
    "            <td>List of predicted labels</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruths</td>\n",
    "            <td>N/A</td>\n",
    "            <td>List of ground truth labels</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">kwargs</td>\n",
    "            <td>predsPath</td>\n",
    "            <td>../results/predictions.txt</td>\n",
    "            <td>Location from where to read predictions from</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruthPath</td>\n",
    "            <td>../results/groundTruths.txt</td>\n",
    "            <td>Location from where to read ground truths from</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blcst.evaluate([col[3] for col in predictions], [col[3] for col in groundTruth], None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
